{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXLo/XqY7es3nyM3zwH6Rc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/igordrodrigues/workshop01122022/blob/main/Mini_Curso_Semana_da_Informatica_Fish_Market.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O primeiro passo é importar as bibliotecas a serem usadas."
      ],
      "metadata": {
        "id": "rzBqj_sYKHRO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wqvrjLerGPhS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em seguida, vamos importar o Data Set"
      ],
      "metadata": {
        "id": "bwTMZ_h0KLBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_url = \"https://raw.githubusercontent.com/igordrodrigues/workshop01122022/main/fish.csv\"\n",
        "fish = pd.read_csv(dataset_url)"
      ],
      "metadata": {
        "id": "AYLXf0qBKLe1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora vamos separar os atributos em uma matriz e os labels em um vetor."
      ],
      "metadata": {
        "id": "LNWFmFyQKOiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = fish.drop(['Species'], axis = 'columns')\n",
        "y = fish.Species"
      ],
      "metadata": {
        "id": "vGPhLRpxKOrw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora iremos dividir nossa amostra em duas partes, uma para o treinamento e outra para testar nosso modelo"
      ],
      "metadata": {
        "id": "MXnONZfXKQr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3,random_state=120)"
      ],
      "metadata": {
        "id": "Ql3rTfkQKQ4C"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em seguida iremos iniciar nosso modelo usando o SVC da sklearn e treinado com nossas amostras de treino. No treinamento o modelo deve ter acesso aos labels corretos, para que possa ajustar a curva de divisão do hiperplano."
      ],
      "metadata": {
        "id": "K5TD_CU5KTQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SVC(kernel = 'linear')\n",
        "model.fit(X_train, y_train) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9Ba4d1SKTYo",
        "outputId": "98b7a392-80ea-4f5d-db12-9965cfc0c0ca"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear')"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com o modelo treinado, iremos pedir que ele faça a predição da amostra de teste, dessa vez ele não terá acesso aos labels."
      ],
      "metadata": {
        "id": "Irlpgtq-KaZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "print (y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNNsr2A6Kai0",
        "outputId": "97e60aa0-e531-4cde-9324-3916990d76d5"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Bream' 'Smelt' 'Bream' 'Parkki' 'Perch' 'Perch' 'Pike' 'Bream' 'Parkki'\n",
            " 'Perch' 'Roach' 'Parkki' 'Roach' 'Smelt' 'Roach' 'Perch' 'Perch' 'Perch'\n",
            " 'Pike' 'Bream' 'Bream' 'Bream' 'Bream' 'Roach' 'Bream' 'Perch' 'Bream'\n",
            " 'Perch' 'Perch' 'Bream' 'Bream' 'Perch' 'Roach' 'Bream' 'Roach' 'Perch'\n",
            " 'Perch' 'Pike' 'Perch' 'Perch' 'Parkki' 'Perch' 'Roach' 'Smelt' 'Perch'\n",
            " 'Pike' 'Perch' 'Whitefish']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora iremos avaliar as métricas dos nossos resultados, comparando os valores previstos pelo nosso modelo com o valor real."
      ],
      "metadata": {
        "id": "Y9zVvsI0Kd4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = model.score(X_test, y_test)\n",
        "sns = metrics.recall_score(y_test, y_pred, average=None, zero_division=1)\n",
        "print('para NONE:\\nACC: ',acc,'\\nSNS (zero division =1): ',sns)\n",
        "sns = metrics.recall_score(y_test, y_pred, average=None, zero_division=0)\n",
        "print('SNS (zero division =0): ',sns)\n",
        "print('Executa o calculo da media de SNS com ponderação:')\n",
        "sns = metrics.recall_score(y_test, y_pred, average='micro', zero_division=1)\n",
        "print('para Micro:    ACC: ',acc,' SNS: ',sns)\n",
        "sns = metrics.recall_score(y_test, y_pred, average='weighted', zero_division=1)\n",
        "print('para Weighted: ACC: ',acc,' SNS: ',sns)\n",
        "print('Executa o calculo da media de SNS sem ponderação:')\n",
        "sns = metrics.recall_score(y_test, y_pred, average='macro', zero_division=1)\n",
        "print('para Macro:    ACC: ',acc,' SNS: ',sns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPjLDv7vKeC3",
        "outputId": "903d6e24-4631-4b86-bfd9-f3eb47e1a7b0"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "para NONE:\n",
            "ACC:  0.9583333333333334 \n",
            "SNS (zero division =1):  [1.         1.         1.         1.         0.77777778 1.\n",
            " 1.        ]\n",
            "SNS (zero division =0):  [1.         1.         1.         1.         0.77777778 1.\n",
            " 1.        ]\n",
            "Executa o calculo da media de SNS com ponderação:\n",
            "para Micro:    ACC:  0.9583333333333334  SNS:  0.9583333333333334\n",
            "para Weighted: ACC:  0.9583333333333334  SNS:  0.9583333333333334\n",
            "Executa o calculo da media de SNS sem ponderação:\n",
            "para Macro:    ACC:  0.9583333333333334  SNS:  0.9682539682539683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos testar um pre-processamento do data-set? Aqui iremos dividir a amostra em treino 1 e preprocessamento, usaremos a amostra de preprocessamento para calibrar um padronizador, em seguida iremos padronizar a amostra treino 1, que em seguida será dividido em treino e teste."
      ],
      "metadata": {
        "id": "W1Rtdqj_Q0lI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train1, X_pre, y_train1, y_pre = train_test_split(X, y, test_size= 0.15,random_state=120)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_pre)\n",
        "X_train1 = scaler.transform(X_train1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train1, y_train1, test_size= 0.2,random_state=120)\n"
      ],
      "metadata": {
        "id": "T_9sNQAXQ0vZ"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora iremos repetir os passos anteriores e ver os resultados"
      ],
      "metadata": {
        "id": "aVbBvzG-Q1A3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SVC(kernel = 'linear')\n",
        "model.fit(X_train, y_train) \n",
        "y_pred = model.predict(X_test)\n",
        "print (y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ykDF2hMQ1Im",
        "outputId": "91e856e4-80b9-458a-c52f-f873a4ada44e"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Perch' 'Parkki' 'Perch' 'Perch' 'Smelt' 'Pike' 'Perch' 'Pike' 'Bream'\n",
            " 'Perch' 'Bream' 'Bream' 'Perch' 'Smelt' 'Perch' 'Smelt' 'Bream' 'Pike'\n",
            " 'Smelt' 'Bream' 'Perch' 'Perch' 'Perch' 'Bream' 'Bream' 'Pike' 'Perch']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = model.score(X_test, y_test)\n",
        "sns = metrics.recall_score(y_test, y_pred, average=None, zero_division=1)\n",
        "print('para NONE:\\nACC: ',acc,'\\nSNS (zero division =1): ',sns)\n",
        "sns = metrics.recall_score(y_test, y_pred, average=None, zero_division=0)\n",
        "print('SNS (zero division =0): ',sns)\n",
        "print('Executa o calculo da media de SNS com ponderação:')\n",
        "sns = metrics.recall_score(y_test, y_pred, average='micro', zero_division=1)\n",
        "print('para Micro:    ACC: ',acc,' SNS: ',sns)\n",
        "sns = metrics.recall_score(y_test, y_pred, average='weighted', zero_division=1)\n",
        "print('para Weighted: ACC: ',acc,' SNS: ',sns)\n",
        "print('Executa o calculo da media de SNS sem ponderação:')\n",
        "sns = metrics.recall_score(y_test, y_pred, average='macro', zero_division=1)\n",
        "print('para Macro:    ACC: ',acc,' SNS: ',sns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBQGrPzvQ1X7",
        "outputId": "8a8d3174-1f9f-43a8-83ef-95448bacbb05"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "para NONE:\n",
            "ACC:  0.8148148148148148 \n",
            "SNS (zero division =1):  [1. 1. 1. 1. 0. 1. 0.]\n",
            "SNS (zero division =0):  [1. 1. 1. 1. 0. 1. 0.]\n",
            "Executa o calculo da media de SNS com ponderação:\n",
            "para Micro:    ACC:  0.8148148148148148  SNS:  0.8148148148148148\n",
            "para Weighted: ACC:  0.8148148148148148  SNS:  0.8148148148148148\n",
            "Executa o calculo da media de SNS sem ponderação:\n",
            "para Macro:    ACC:  0.8148148148148148  SNS:  0.7142857142857143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nem sempre o pre-processamento contribui para melhorar os resultados, por isso é importante conhecer o problema que deseja resolver, para avaliar a melhor forma de desenhar o experimento."
      ],
      "metadata": {
        "id": "duERskgKQ1et"
      }
    }
  ]
}